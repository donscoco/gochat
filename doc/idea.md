



# 业务数据持久化设计

需要持久化的数据主要分为几个板块

- 用户个人信息
- 好友关系信息
- 群组关系信息
- 会话信息
- 消息数据





会话消息因为需要保证消息的时序一致性，为用户的会话维护一个消息队列，但是因为用户很多，不可能是一个真的队列，所以可以理解为一个抽象的队列，然后需要记录每个用户对这些数据的读写情况，所以需要记录每个用户的在这个会话的 读写offset。所以可以确定消息模块的表结构

Message : [ uid, fid, content, sequence ].  到时候根据seq排序后就是一条抽象的队列

Conversation : [ uid, fid, read_offset, write_offset ]. 记录每个用户在这个会话中的读写偏移情况。用户读写消息就同时更新这个offset



# 缓存设计

缓存的key设计：

- 观察业务查询数据是如何查询的，例如查询mysql的时候的sql语句的 where 条件是什么，可以使用where 的条件作为缓存的key，查询出来的结果作为缓存的value。

- 将 查询的 key提出来后主要有以下几种缓存

  - prefix_{uid} : { 用户信息 }

  - prefix_{uid_fid} : { 用户好友关系信息 }

  - prefix_{uid} : { 用户好友列表 }

  - prefix_{gid}：{群组信息}

  - prefix_{gid}：{群组的所有成员}

  - prefix_{uid}：{用户所属群组id}

  - prefix_{uid_fid}：{用户在这个私聊会话中的 读 offset}

  - prefix_{uid_fid}：{用户在这个私聊会话中的 写 offset}

  - prefix_{uid_gid}：{用户在这个群会话中的 读 offset}

  - prefix_{uid_gid}：{用户在这个群会话中的 写 offset}

  - prefix_{gid}：{群聊会话中最近7天的消息数据}

  - prefix_{uid_fid}：{私聊会话汇总最近30天的消息数据}

    

二级缓存：

- 对于不怎么变动的数据，缓存在本地（进程的内存中，例如用一个封装的map来存放数据），减少网络延迟带来的耗时。
- 对于共享类的数据或者对数据实时性要求比较高的才存放在一些共享/临界资源上（如放在 redis,aerospike等数据存储服务上）
- 从降低延迟（本地缓存）和降低内存成本（aerospike这种用ssd作为缓存介质的）的角度考虑

采用旁路缓存设计：

- 写操作：先写数据库，后删除缓存
- 读操作：先读取缓存，没有就查询数据库后设置到缓存

应对 缓存击穿

- 添加锁，golang 官方提供的扩展包可以直接使用 singleflight

应对 缓存穿透

- 放一个空key（目前先这样简单做，后续考虑是否使用布隆过滤器）
- 布隆过滤器





# 消息系统设计

## 消息可靠性保证

如何保证消息不丢失？

如何保证消息不重复？

如何保证消息的时序一致性？

tcp是保证包内数据片段不丢失，不能保证上交给应用层后，应用层能处理好。例如tcp交给应用层后，应用层宕机了。消息没能处理保存，tcp在这之中已经完成了从端到端的可靠 传输，不关tcp的事。这里可以参考tcp是如何实现可靠传输的，在应用层也使用类似的机制去做。例如在应用层加入 seq和ack的概念。为每条消息分配一个sequence，接收方处理完之后才发ack确认给发送方，如果发送方没有收到接收方的ack，会每隔一段时间后重试发送。这样就确保数据不丢失。在保证消息不重复上，我们在处理消息的seq上，用双id链（或者说版本号）来实现消息不重复，本质就是维护前一个seq。或者直接使用一个set来去重。在保证消息时序上，只要保证seq是单调递增的，结合前面双id链/版本号更新，发送方没有收到ack会重发。就可以实现时序一致性。这里我们使用雪花算法来生成seq。

## 消息推送

读扩散问题和写扩散问题

写扩散就是在群聊场景发送方每发送一条数据，我们就要发送这个数据给所有接收方，这样导致用户发送一条数据，系统就有对应产生很多条重复的数据，这样不利于系统的稳定性。为了应对这种情况，采用推拉结合的方式，发送方的数据保存起来。然后将这个"群聊"抽象成一条"队列"，只要通知所有接收方自己来查询。而接收方事先维护好一个offset，这个offset就是队列的偏移，接收方查询这条"群聊队列"的大于接收方offset的最新消息就行。



为了提高系统稳定性，使用推拉结合的方式



如何知道要推送的conn（fd）在哪台机器上？

每个登陆的用户定时通过websocket 发送心跳，conn_engine 将用户id:所在机器ip进行映射。



心跳保活

确认客户端存活不能只靠长链接，因为运营商可能会检测并断开连接。所以心跳的确认，只靠tcp的保持长链接而不传数据的方式是不行的。客户端和服务端之间要要定时有数据传输。同时，服务端会维持很多连接，如果让服务端来传输数据，1s内向所以客户端发送数据做不到。所以设计成客户端每隔一段时间就向服务端发送心跳来确保客户端连接存活



断线重连

如客户端网络不稳定，网络断开场景怎么处理？等待客户端重连，延长心跳信息和session等信息



心跳风暴



可观测指标

todo 使用 promethus+grafana，ELK



分布式链路追踪

todo 使用 jeager



如何实现长链接服务热重启？（fd怎么继承？）fork 子进程



